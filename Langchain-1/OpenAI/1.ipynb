{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "# LangSmith Tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHIAN_TRACING_V2'] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000002FB1CAF6F50> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002FB1CBCA200> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a response from LLM\n",
    "result = llm.invoke(\"Describe about yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence developed by OpenAI, designed to assist with a wide range of queries and tasks. My capabilities include answering questions, providing explanations, generating text, and offering assistance with various topics. I don't have personal experiences, emotions, or a physical presence, but I'm programmed to understand and generate human-like text based on the information and patterns within the data I've been trained on.\n",
      "\n",
      "Feel free to ask me anything you'd like to know or need help with!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an AI Engineer. Please provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an AI Engineer. Please provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! LangSmith is a suite of tools designed to enhance the development, evaluation, and monitoring of applications built with the LangChain framework. Here are some key features and functionalities of LangSmith:\n",
      "\n",
      "1. **Tracer Tool**: \n",
      "   - **Purpose**: To trace and visualize the execution of LangChain applications.\n",
      "   - **Benefits**: Helps in understanding the flow of data, identifying bottlenecks, and debugging complex chains.\n",
      "\n",
      "2. **Evaluation Tool**:\n",
      "   - **Purpose**: To evaluate the performance of different chains and language models.\n",
      "   - **Benefits**: Assists in selecting the best models and chains by providing insights into their accuracy, efficiency, and effectiveness.\n",
      "\n",
      "3. **Monitoring Tool**:\n",
      "   - **Purpose**: To monitor the ongoing performance and health of LangChain applications.\n",
      "   - **Benefits**: Ensures that applications are running smoothly and efficiently, and helps in quickly identifying and resolving issues.\n",
      "\n",
      "4. **Integration with LangChain**:\n",
      "   - **Compatibility**: Seamlessly integrates with LangChain applications, making it easy to incorporate these tools into existing workflows.\n",
      "   - **Usability**: Designed to be user-friendly, catering to developers of varying skill levels.\n",
      "\n",
      "LangSmith aims to simplify the process of building robust, efficient, and reliable LangChain applications by providing essential tools for tracing, evaluating, and monitoring.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool designed to enhance the development, testing, and monitoring of applications that utilize language models. It offers a range of features aimed at improving the performance and reliability of these applications. Here are some key aspects of LangSmith:\n",
      "\n",
      "1. **Tracing**: LangSmith provides tracing capabilities to help developers understand the sequence of events and interactions within their language model applications. This is crucial for debugging and optimizing performance.\n",
      "\n",
      "2. **Evaluation**: It includes tools for evaluating the output of language models, allowing developers to assess the quality and accuracy of the generated text. This helps in fine-tuning models for better results.\n",
      "\n",
      "3. **Monitoring**: LangSmith offers monitoring features to keep track of the application's performance in real-time. This ensures that any issues can be quickly identified and addressed.\n",
      "\n",
      "4. **Integration with LangChain**: LangSmith is designed to work seamlessly with LangChain, a framework for developing applications powered by language models. This integration simplifies the development process and enhances the capabilities of language model applications.\n",
      "\n",
      "Overall, LangSmith is a comprehensive solution for developers working with language models, providing the tools needed for effective development, evaluation, and monitoring.\n",
      "\n",
      "If you have any specific questions or need more detailed information about LangSmith, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Default o/p Parser strouput\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
